---
title: "A log-ratio approach to cluster analysis of count data when the total is irrelevant"
subtitle: ""
author: "Marc Comas-Cufí"
institute: "Department of Computer Science, Applied Mathematics and Statistics"
date: "(updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, include=FALSE}
set.seed(1)
library(knitr)
library(flextable)
library(ggplot2)
library(ggtern)
library(coda.base)
library(coda.count)
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = TRUE, comment = '#> ')
# print.matrix = function(x, ...){
#   print(class(x))
#   if(is.matrix(x)){
#     print.default(round(x, 3), ...)
#   }else{
#     print.default(x, ...)
#   }
# }
```

class: top

#### Multivariate count data: **Multinomial** vs **Multivariate Poisson**

* Without variability in their parameters (with constant parameters).
    * Parts of __multivariate Poisson__ observations are independent. 
    * Parts of __multinomial__ observations are negatively correlated $\implies$ Tendency of negative bias $\implies$ interpretation about association of parts can not depend on $cov(X_i,X_j)$.

--

```{r}
N = 1000000; LAMBDA = c(2,2,4); PI = c(0.25,0.25,0.5)

cor(sapply(LAMBDA, rpois, n = N))
cor(coda.count::rmultinomial(n = N, size = 8, p = PI))
```

---

#### Multivariate count data: **Multinomial** vs **Multivariate Poisson**

* Without variability in their parameters (with constant parameters).
    * Parts of __multivariate Poisson__ observations are independent. 
    * Parts of __multinomial__ observations are negatively correlated


In other words,

* $\text{cov}(X_i,X_j) = 0$ for the __multivariate Poisson__.
* $\text{cov}(X_i,X_j) < 0$ $\implies$ Tendency of negative bias $\implies$ interpretation about association of parts can not depend on $\text{cov}(X_i,X_j)$.

---

#### Relation to strictly positive samples

* __Multivariate Poisson__ distributed data $\iff$ __Log-normally__  distributed data
* __Multinomial__ distributed data $\iff$ __Log-ratio-normally__  distributed data

```{r}
N = 1000000; MU = c(2,2,3)
lnX = exp(sapply(MU, function(m) rnorm(n=N,m)))

cor(lnX)
cor(lnX/rowSums(lnX))
```

---


#### Parametric approaches to cluster multivariate count data (1)

* __Ignoring compositional variability and ignoring counting variabily__. 
    * Consider data is real, i.e. $X \in \mathbb{R}^d$ and apply classical methods.

--

* __Taking into account counting variability, but ignoring compositional variabity__. Mixtures of multinomials distributions.

--

* __Taking into account compositional variability, but ignoring counting variability__. Zero replacement methods followed by classical compositional methods.
    * Dirichlet Prior (Martin-Fernandez _et al._, 2015)
    * Log-ratio Prior (Comas-Cufí _et al._, 2019)
<!--    * We have $a=b$ when $a = (1,1,2)$, $b=(1000,1000,2000)$. $a$ and $b$ at the same distance than $p=(\frac{1}{3},\frac{1}{3},\frac{1}{3})$. -->

---

#### Parametric approaches to cluster multivariate count data (2)

* __Taking into account compositional and counting nature__.

    * _Topic models_. Mixture of multinomials where mixing proportions are modelled in the Simplex.
    
        * __Latent Dirichlet Allocation__.  Dirichlet distribution. (Blei _et. al., 2003)
        * __Correlated Topic Models__.  Log-ratio normal distribution. (Blei & Lafferty, 2007)
        
    * _Mixture of compounding distributions_.
    
        * __Mixtures of Dirichlet-multinomial distributions__. (Holmes _et al._, 2012)
        * __Mixtures of log-ratio-normal-multinomial distributions__. (Comas-Cufí _et al._, 2017)

---

#### Using classical clustering approach for real data to cluster count data

1. __Dealing with zeros__. Fit a Dirichlet-multinomial distribution to your data.
    * _A Dirichlet prior seems to be conservative in keeping the covariance structure observed in count data_.  Regression toward the mean is moderate.
1. __Compositional variability__. Fit a mixture of log-ratio spherical Gaussian distributions to the posterior probabilities.
1. __Counting variability__. Create $B$ new samples using the posterior distribution and find a cluster using a classical method.
1. __Combining results__. Use cumulative voting (Dudoit & Fridlyand, 2003) to build a cluster.

---

### Simple example based on 2017 catalan parliament elections

```{r}
load('parliament2017.RData')
head(parliament)
```


---

### We only consider three parts

```{r, eval=FALSE}
Y = matrix(0, nrow = nrow(X), ncol = 3)
Y[,1] = with(parliament, catsp+other)
Y[,2] = with(parliament, cup+jx)  X[,'cup'] + X[,'catsp'] + X[,'erc']
Y[,3] = X[,'pp'] + X[,'cs'] + X[,'psc']
colnames(Y) = colnames(X)
colnames(Y) = c('other', 'ind', 'esp')
head(Y)
```


---

#### Dealing with zeros



#### Compositional variability

---

#### Conclusions

* We have seen different approaches to cluster count data when only the relative relation relation between parts was of interest.
* Methods using compositional covariance (those based on the normality) have very limited applicability. They are computational demanding.
* A parsimonious approach can be constructed in such a way that the variability comming from a multinomial counting process can be incorporated to the observed compositional variability.
* To study the final clustering using the different clustering. Consensus clustering technics can be used.
